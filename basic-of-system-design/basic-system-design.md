# Network Performance Concepts

## âš™ï¸ 1. Bandwidth â€” Maximum capacity
### ğŸ” What is it?
Bandwidth is the maximum amount of data that can be transferred per second over a network connection.

Think of it as the width of a highway â€” the wider the road, the more cars can travel side-by-side.

### ğŸ“ Measured In:
- Mbps (Megabits per second)
- Gbps (Gigabits per second)

### ğŸ’¡ Example (Backend):
If your server has 1 Gbps bandwidth, that means up to 125 MB/s of data can be transferred (1 byte = 8 bits).

But remember: Bandwidth is just the maximum potential, not the actual speed.

## âš™ï¸ 2. Throughput â€” Actual performance
### ğŸ” What is it?
Throughput is the actual amount of data transferred per second, considering real-world conditions (like congestion, server load, etc).

Itâ€™s the number of cars that actually pass on the highway per second, not the theoretical max.

### ğŸ“ Measured In:
Same as bandwidth â€” Mbps or Gbps

### ğŸ’¡ Example (Backend):
Your server has 1 Gbps bandwidth, but if youâ€™re transferring files and only getting 400 Mbps, then your throughput = 400 Mbps (maybe due to DB bottleneck or TCP retries).

## âš™ï¸ 3. Latency â€” Delay or waiting time
### ğŸ” What is it?
Latency is the time it takes for data to travel from source to destination â€” usually measured as Round Trip Time (RTT).

Like the time it takes for a message to reach and come back.

### ğŸ“ Measured In:
Milliseconds (ms)

### ğŸ’¡ Example (Backend):
If your frontend client in Tokyo calls a backend server in New York:

- Ping time might be 200 ms

Thatâ€™s latency: how long it takes for a request to reach the server and come back.

## ğŸ§  Real-World Analogy (Download Water Example)
| Concept   | Analogy                     | Network Example                 |
|-----------|-----------------------------|---------------------------------|
| Bandwidth | Size of the pipe            | Max 100 Mbps internet line      |
| Throughput| Water actually flowing      | Getting 40 Mbps download        |
| Latency   | Delay before water starts   | 150ms delay before loading API  |

## ğŸ§ª Backend-Specific Examples
### âœ… File Download:
- **Bandwidth** = 100 Mbps line
- **Throughput** = 85 Mbps actual download rate
- **Latency** = 50ms from client to server

### âœ… API Call:
Fast backend, but:
- **High latency (200ms)** â†’ because server is far away
- **Low throughput** â†’ client has slow 3G connection

### âœ… Streaming Logs:
You need high throughput and low latency

If latency is too high, real-time logs feel delayed

## ğŸ”¥ Why Backend Engineers Must Understand These:
| Impact Area           | How It Affects You                                      |
|-----------------------|---------------------------------------------------------|
| API Performance       | High latency = slow UX even if logic is fast            |
| File Upload/Download  | Throughput affects time to complete                     |
| Microservices         | Internal API calls across services = latency-sensitive  |
| Database Replication  | Bandwidth needed for syncing large volumes             |
| Monitoring & Alerts   | Delay in logs or metrics = delayed insight             |

## ğŸ› ï¸ Tools to Measure:
| Metric     | Tool                          |
|------------|-------------------------------|
| Bandwidth  | speedtest, iperf              |
| Throughput | iperf, system metrics         |
| Latency    | ping, traceroute, curl -w "%{time_total}" |

## âœ… Summary Table
| Metric     | Description                        | Measured In | Keyword Analogy           |
|------------|------------------------------------|-------------|---------------------------|
| Bandwidth  | Max data capacity                  | Mbps        | Highway width             |
| Throughput | Actual data being transferred      | Mbps        | Cars passing per second   |
| Latency    | Delay before/while sending data    | ms          | Time to start flow        |






# Understanding APIs and REST APIs

## âœ… What is an API?
API stands for Application Programming Interface.

### ğŸ“¦ Definition:
It is a set of rules and protocols that allows different software systems or components to communicate with each other.

### ğŸ§  Analogy:
Think of an API like a restaurant menu.  
You (the frontend) choose a dish (send a request) â†’ the kitchen (backend) prepares it â†’ and the waiter (API) delivers it to you.

### âœ… Real-World Example:
Suppose you use a weather app on your phone:  
- The app sends a request to a Weather API like `GET /weather?city=London`  
- The Weather API (hosted by the backend) responds with JSON:

```json
{
  "temperature": "27Â°C",
  "condition": "Sunny"
}
```

## âœ… What is a REST API?
REST stands for Representational State Transfer.  
Itâ€™s a design pattern for building APIs using HTTP and resource-based structure.

### ğŸ§  Core Concepts of REST:
- **Resources**: Everything is treated as a resource (e.g., users, posts, products)
- **HTTP Verbs**:
  - **GET**: Fetch a resource
  - **POST**: Create a new resource
  - **PUT/PATCH**: Update a resource
  - **DELETE**: Delete a resource
- **Stateless**: Every request from the client must contain all the info needed.
- **Uniform Interface**: Same rules for all resources (use URIs).

## âœ… What is a RESTful API?
RESTful API is simply an API that follows the REST principles.

So:
- **REST API**: refers to the architectural concept.
- **RESTful API**: refers to an API implementation that actually follows the REST rules.

ğŸ‘‰ Many people use "REST API" and "RESTful API" interchangeably.

## âœ… RESTful API Example (Blog App)
Suppose you have a blog app with posts.

### Endpoints:
| Operation       | HTTP Method | URL          | Description              |
|-----------------|-------------|--------------|--------------------------|
| Get all posts   | GET         | /posts/      | List all blog posts      |
| Get one post    | GET         | /posts/5/    | Get post with ID 5       |
| Create new post | POST        | /posts/      | Add a new blog post      |
| Update post     | PUT/PATCH   | /posts/5/    | Edit post with ID 5      |
| Delete post     | DELETE      | /posts/5/    | Delete post with ID 5    |

### Sample Response (GET /posts/5/):
```json
{
  "id": 5,
  "title": "What is REST?",
  "content": "REST is a set of principles...",
  "author": "Rabbi"
}
```

## âœ… Trade-offs of RESTful API
### âœ… Advantages:
| Advantage       | Explanation                                                  |
|-----------------|--------------------------------------------------------------|
| ğŸŒ Stateless     | Scales easily since server doesnâ€™t store client state.       |
| ğŸ” Cacheable    | Responses can be cached to improve speed.                    |
| ğŸ“ Standardized  | Easy to understand and follow (common HTTP methods).         |
| ğŸ”§ Flexible      | Works with any frontend (React, mobile, etc.)                |

### âŒ Disadvantages:
| Disadvantage       | Explanation                                                  |
|--------------------|--------------------------------------------------------------|
| ğŸ“¦ Over-fetching   | You might get more data than needed (GET /users returns too much). |
| ğŸ” Multiple requests | Nested resources often need extra API calls.                |
| ğŸ“š Too generic     | REST doesnâ€™t define how to handle versioning, filtering, sorting, etc. |
| ğŸš¦ No real-time    | REST is request/response; doesnâ€™t support push like WebSockets. |

## âœ… When to Use REST APIs
Use REST APIs when:
- You need a clean, simple, stateless interface.
- Your system is CRUD-heavy (e.g., e-commerce, blogs, admin dashboards).
- You want broad compatibility with frontend/mobile frameworks.






# Understanding Scaling

ğŸ” **What is Scaling?**  
Scaling is the process of increasing your system's capacity to handle more users, more requests, or more data.

There are two main types:  
- **Vertical Scaling (Scale Up)**  
- **Horizontal Scaling (Scale Out)**  

## 1ï¸âƒ£ Vertical Scaling (Scaling Up)
### ğŸ“¦ Definition:
Increasing the resources (CPU, RAM, SSD, etc.) of a single server.

### ğŸ§  Analogy:
Upgrading your laptop from 8 GB RAM to 32 GB RAM so it runs faster.

### âœ… Example:
Suppose you run a web server on a VM with:  
- 2 CPUs  
- 4 GB RAM  

Now you upgrade to:  
- 8 CPUs  
- 32 GB RAM  

The server can now handle more users without changing your code or infrastructure.

### âœ… Pros:
| Advantage                          | Explanation                                                  |
|------------------------------------|--------------------------------------------------------------|
| âœ… Simple to implement              | No code/config changes needed. Just upgrade hardware.         |
| âœ… No distributed system complexity | No need to manage multiple servers.                          |
| âœ… Lower latency                    | Everything runs on one machine (no network hops).             |

### âŒ Cons:
| Disadvantage                      | Explanation                                                  |
|-----------------------------------|--------------------------------------------------------------|
| âŒ Expensive                       | High-end hardware gets costly quickly.                       |
| âŒ Single Point of Failure         | If the server dies, everything goes down.                    |
| âŒ Limited ceiling                 | You can only upgrade hardware to a point (you'll eventually hit a limit). |
| âŒ Downtime required               | Often need to restart to scale up.                           |

## 2ï¸âƒ£ Horizontal Scaling (Scaling Out)
### ğŸ“¦ Definition:
Adding more servers/nodes to your system to share the load.

### ğŸ§  Analogy:
Instead of hiring one superhuman to do everything, you hire 5 normal people to divide the work.

### âœ… Example:
Suppose you have one web server running a Django app. Now traffic increases.  

You add:  
- 3 more servers (so total 4)  
- Use a load balancer (like Nginx, HAProxy




# Understanding Load Balancers

## ğŸ§­ What is a Load Balancer?
### âœ… Definition:
A load balancer is a system (hardware or software) that distributes incoming network traffic across multiple servers (backend nodes) to:  
- Improve performance  
- Avoid overloading any single server  
- Ensure high availability  

### ğŸ§  Analogy:
Imagine youâ€™re at a busy restaurant. Thereâ€™s a receptionist (load balancer) who assigns customers to available tables (servers) so no waiter gets overwhelmed.

### ğŸ”§ Load Balancer Working Flow
```
Client â†’ Load Balancer â†’ Multiple Servers
```

**Example:**
```
Client â†’ Load Balancer â†’ [Server A, Server B, Server C]
```
The load balancer chooses the best server based on a balancing algorithm.

## ğŸ§± Types of Load Balancer
| Type                     | Description                                                  |
|--------------------------|--------------------------------------------------------------|
| ğŸ§  Software Load Balancer | Runs on Linux/macOS/Windows as a service (e.g., Nginx, HAProxy) |
| ğŸ§± Hardware Load Balancer | Physical devices (e.g., F5, Cisco) used in data centers       |
| â˜ï¸ Cloud Load Balancer   | Managed service by cloud providers (AWS ELB, GCP Load Balancer, Azure ALB) |

## âš–ï¸ Types by Layer
| Layer   | Type                   | Description                                                  |
|---------|------------------------|--------------------------------------------------------------|
| Layer 4 | Transport Layer LB     | Balances TCP/UDP traffic (e.g., IP + Port)                   |
| Layer 7 | Application Layer LB   | Makes decisions based on HTTP headers, URLs, cookies, etc. (e.g., route /api/ to API server) |

## ğŸ§  6 Most Common Load Balancing Algorithms
### 1ï¸âƒ£ Round Robin
**ğŸ¯ What:**  
Distributes requests one-by-one to servers in a circular order.

**âš™ï¸ Example:**  
- Request 1 â†’ Server A  
- Request 2 â†’ Server B  
- Request 3 â†’ Server C  
- Request 4 â†’ Server A  
...

**âœ… Pros:**  
- Simple  
- Works well when all servers are equal in capacity  

**âŒ Cons:**  
- Doesn't consider server load or response time  

### 2ï¸âƒ£ Weighted Round Robin
**ğŸ¯ What:**  
Same as Round Robin, but gives more traffic to more powerful servers.

**âš™ï¸ Example:**  
- Server A: weight 2  
- Server B: weight 1  
- Requests â†’ A, A, B, A, A, B...  

**âœ… Pros:**  
- Better for heterogeneous servers  
- Easy to configure  

**âŒ Cons:**  
- Doesn't adapt dynamically to real-time load  

### 3ï¸âƒ£ Least Connections
**ğŸ¯ What:**  
Sends traffic to the server with the fewest active connections.

**âœ… Pros:**  
- Great when sessions/requests are long-lived  
- Efficient for real-time apps  

**âŒ Cons:**  
- Slight overhead in tracking connection count  
- Doesnâ€™t consider server response time  

### 4ï¸âƒ£ Weighted Least Connections
**ğŸ¯ What:**  
Like Least Connections, but uses server weights to prefer stronger machines.

**âœ… Pros:**  
- Balances long sessions more intelligently  
- Works well with mixed-capacity servers  

**âŒ Cons:**  
- More complex to configure  

### 5ï¸âƒ£ IP Hash (Source IP Affinity)
**ğŸ¯ What:**  
Uses the client's IP address to always route the same client to the same server.

**âš™ ê¸ˆìœµ Example:**  
- User from IP 192.168.1.2 â†’ always goes to Server A  
- Sticky sessions behavior.

**âœ… Pros:**  
- Good for session persistence  
- Reduces cache invalidation  

**âŒ Cons:**  
- Uneven traffic distribution  
- Can break if IP address changes (mobile users)  

### 6ï¸âƒ£ Least Response Time
**ğŸ¯ What:**  
Chooses the server with the fastest current response time.

**âœ… Pros:**  
- Ideal for low-latency apps  
- Adapts to real-time performance  

**âŒ Cons:**  
- Needs performance monitoring  
- May require additional software or custom logic  

## ğŸ†• 1ï¸âƒ£ Sticky Round Robin
**ğŸ¯ What is it?**  
Sticky Round Robin (also called Session-Aware Round Robin) is a hybrid:  
- It combines Round Robin with session persistence ("stickiness").  
- Once a client is assigned to a server, all future requests from that client go to the same server, until a timeout or logout.

**ğŸ§  Example:**  
You have 3 servers: A, B, and C  

| Request | Client IP     | Assigned Server        |
|---------|---------------|------------------------|
| 1       | 192.168.1.2   | A (via Round Robin)    |
| 2       | 192.168.1.3   | B                      |
| 3       | 192.168.1.2   | A (Sticky: same as before) |
| 4       | 192.168.1.4   | C                      |

**âœ… Pros:**  
| Advantage                     | Explanation                                                  |
|-------------------------------|--------------------------------------------------------------|
| âœ… Maintains session state     | Good for login, shopping carts, etc.                         |
| âœ… Balanced over time          | Still distributes new sessions fairly                        |

**âŒ Cons:**  
| Disadvantage                  | Explanation                                                  |
|-------------------------------|--------------------------------------------------------------|
| âŒ May cause imbalance         | If too many clients "stick" to the same server               |
| âŒ Session tracking needed     | Usually via cookies, tokens, or IP address                   |
| âŒ Not scalable alone         | Needs backup handling if a server goes down                  |

## ğŸ§ª Real-Life Load Balancer Examples
| Tool / Service      | Type                  | Description                               |
|---------------------|-----------------------|-------------------------------------------|
| ğŸ§° Nginx            | Software (Layer 7)    | Reverse proxy and load balancer           |
| ğŸ§° HAProxy          | Software (Layer 4/7)  | High performance TCP/HTTP LB              |
| â˜ï¸ AWS ELB         | Cloud LB (L4/L7)      | Elastic Load Balancer                     |
| â˜ï¸ Google Cloud LB | Cloud LB (L4/L7)      | Global load balancing                     |
| âš™ï¸ Envoy Proxy      | Modern proxy          | Advanced LB + observability               |
| ğŸ§± F5 BIG-IP        | Hardware (Enterprise) | Enterprise-grade LB device                |

## ğŸ“Š Comparison Table of Algorithms
| Algorithm              | Traffic Awareness       | Server Health         | Session Stickiness | Use Case Example           |
|------------------------|-------------------------|-----------------------|--------------------|---------------------------|
| Round Robin            | âŒ Equal only           | âŒ No                 | âŒ No              | Simple app with equal servers |
| Weighted Round Robin   | âœ… Weighted             | âŒ No                 | âŒ No              | Mixed servers             |
| Least Connections      | âœ… Yes                  | âŒ No                 | âŒ No              | Chat apps, video streaming |
| Weighted Least Conn    | âœ… Yes + weights        | âŒ No                 | âŒ No              | Microservices with variance |
| IP Hash                | âŒ No                  | âŒ No                 | âœ… Yes             | Login sessions, carts     |
| Least Response Time    | âœ… Fastest wins         | âœ… Needs monitor       | âŒ No              | Low-latency APIs          |

## ğŸ Summary
| Concept               | Vertical Scaling       | Horizontal Scaling                          |
|-----------------------|------------------------|---------------------------------------------|
| Load Balancer Role    | Not needed             | Essential to distribute load                |

## ğŸ”š Final Thoughts
Load balancers are critical in any production-grade distributed system.  

Choosing the right algorithm depends on:  
- **Server types** (homogeneous vs heterogeneous)  
- **Type of traffic** (short requests vs long sessions)  
- **Performance needs** (latency vs throughput)  

You can often combine multiple strategies (e.g., weighted + least connections).



# Understanding API Gateways

## ğŸšª What is an API Gateway?
An API Gateway is a reverse proxy that sits between your client (frontend/mobile) and backend services (microservices, monoliths, etc.). It acts as a single entry point that handles:

- Routing requests to the right service
- Security (JWT validation, OAuth, API keys)
- Rate limiting
- Logging & monitoring
- Load balancing
- Request transformation

**Think of it as the traffic controller for all your APIs.**

## ğŸ§± Why Use an API Gateway?
**Without a gateway**, clients must:
- Call each microservice directly
- Handle security, retries, discovery, etc.
- Be tightly coupled to backend structure

**With a gateway**:
- One consistent entry point (e.g., `api.yourapp.com`)
- Internal services are hidden and protected
- Centralized security, analytics, throttling

## ğŸ› ï¸ Core Features of API Gateways
| Feature             | Description                                                  |
|---------------------|--------------------------------------------------------------|
| **Routing**         | Route `/api/users` to user-service, `/api/orders` to order-service |
| **Authentication**  | Validate JWTs, OAuth2 tokens, API keys                       |
| **Rate Limiting**   | Protect backend from abuse (e.g., 100 req/min per IP)        |
| **Caching**         | Cache GET responses to reduce load                           |
| **Load Balancing**  | Distribute traffic across multiple instances                 |
| **Request Rewriting**| Modify headers, paths, or payloads                           |
| **Monitoring**      | Access logs, latency, status codes                          |
| **CORS Handling**   | Allow frontend domains to access APIs                        |

## âš™ï¸ Common API Gateway Software
You have two main categories: **open-source (self-hosted)** and **managed (cloud-based)**.

### âœ… 1. Open Source / Self-Hosted Gateways
These are tools you run yourself â€” in Docker, Kubernetes, or on VMs.

#### ğŸ”¹ Kong
- Built on NGINX + Lua
- Plugin-based architecture
- Has both OSS and Enterprise versions
- Supports JWT, rate limiting, logging, transformations
- Admin API for dynamic configuration
- **â¡ï¸ Good for**: medium to large production systems with plugin needs
- **ğŸ”—** https://konghq.com

#### ğŸ”¹ NGINX
- Powerful reverse proxy and load balancer
- Can be configured as API gateway
- Supports JWT validation via Lua or third-party modules
- Extremely performant
- **â¡ï¸ Good for**: low-level control, performance-focused apps
- **ğŸ”—** https://nginx.org

#### ğŸ”¹ Traefik
- Modern, cloud-native, dynamic gateway
- Auto-discovers services in Docker/Kubernetes
- Built-in support for TLS, Let's Encrypt
- Lightweight and easy to deploy
- **â¡ï¸ Good for**: containerized environments
- **ğŸ”—** https://traefik.io

#### ğŸ”¹ Envoy
- High-performance proxy created by Lyft
- Used in Istio and modern service mesh stacks
- Full support for observability, retries, timeouts
- Complex config but very powerful
- **â¡ï¸ Good for**: service mesh / enterprise-grade setups
- **ğŸ”—** https://www.envoyproxy.io

#### ğŸ”¹ KrakenD
- API gateway focused on performance
- Combines and filters multiple backend responses
- Low-latency, easy to configure JSON-based system
- **â¡ï¸ Good for**: API aggregation or BFF (Backend for Frontend)
- **ğŸ”—** https://www.krakend.io

### âœ… 2. Managed API Gateways (Cloud Providers)
These are fully managed, no-infrastructure gateways â€” you configure via UI or CLI.

#### â˜ï¸ AWS API Gateway
- Supports REST and WebSocket APIs
- Integrates with Lambda, ECS, IAM
- Built-in JWT/OAuth2 validation
- Throttling, logging, and WAF support
- **ğŸ”—** https://aws.amazon.com/api-gateway/

#### â˜ï¸ Google Cloud API Gateway / Apigee
- Secure and manage APIs at scale
- Apigee supports API monetization, policy control
- Great analytics
- **ğŸ”—** https://cloud.google.com/api-gateway  
- **ğŸ”—** https://cloud.google.com/apigee

#### â˜ï¸ Azure API Management
- Full API lifecycle management
- Supports policies, quotas, CORS, OpenAPI
- Integration with Azure Active Directory
- **ğŸ”—** https://azure.microsoft.com/en-us/products/api-management/

#### â˜ï¸ Cloudflare API Gateway
- Built-in WAF, DDoS protection
- Extremely fast at edge locations
- Rules-based routing
- **ğŸ”—** https://developers.cloudflare.com/api-shield/

## ğŸ“Œ When Should You Use an API Gateway?
**Use one if you**:
- Have microservices architecture
- Need centralized security & throttling
- Expose public APIs
- Support multiple clients (web, mobile, IoT)

**You might skip it if**:
- Youâ€™re building a monolith
- Everything is internal and low-scale